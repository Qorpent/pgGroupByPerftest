pgGroupByPerftest
=================

Вспомогательный проект для оценки производительности разных планов под GroupBy на postgresql

B данном приложении изучается проблема неэффективного GROUP BY при работе с большими таблицами (без WHERE) из POSTGRESQL

Суть проблемы в том, что индексы в постгрес не могут хранить неключевые значения, а статистика не является доверенным
объектом постгреса и соответственно все запросы по любым полям c GROUP BY используют SEQ SCAN таблицы.

Устройство тестовой среды.

1. Имеется скрипт https://github.com/Qorpent/pgGroupByPerftest/blob/master/testbench.sql, который позволяет создать тестовую среду в целевой БД Postgres (внимательно, часть опасных операций закоментирована и должна применяться отдельно под особым контролем). В среду входят представления для генерации контента и 15 таблиц - 1 является таблицей на 10 млн. записей. Другие 14 это те же 10 млн, но разбитые на партиции по 2 на год (по полугодиям) в качестве тестовых данных генерятся пары дата-значение по диапазону дат от 01.01.2001 до  31.12.2007 (2556 дней). 
2. Здесь же в скрипте уже есть закоментированный скрипт "наката" тестовых данных в таблицу
3. Здесь же несколько типов запросов делающих GROUP BY по всей таблице или по партициям с разными планами
4. Приложение на C#, CLI (.NET/MONO-совместимое), которое является бенчмарком но с дополнительными свойствами: скрипты из БД выполняются по 10 раз с замером производительности, имеется собственная альтернатива, которая выполняет одновременный многопоточный доступ к партициям.
5. Это обычная консоль - вызывается, цепляется к БД по умолчанию к базе test с учеткой процесса (Integrated) если нужна другая строка подключения - указать первым параметром при вызове используя нотацию NPGSQL - http://www.connectionstrings.com/postgre-sql

Результаты тестов на Lenowo W510 под управлением Win 8  приведены в https://github.com/Qorpent/pgGroupByPerftest/blob/master/2013_03_16_LenowoW510_Paralel_Result.txt

Предварительные результаты:
1. Работа с таблицей напрямую дает среднуюю скорость 4+ секунды и имеет тенденцию к скачкам
2. Работа с партициями в модели UNION + GROUP BY - это самый плохой вариант - скачет от 5 до 15 секунд
3. Работа с партициями в модели GROUP BY + UNION и особенно GROUP BY + UNION ALL - самый быстрвый вариант для простого запроса в POSTGRES, дает время 3,5- 3,8 секунды
4. При работе в паралельном режмиме даже без оптимизаций обеспечивается существенный прирост производительности - среднее время выполнения составляет 1,7 - 1,9 секунды, что быстрее варианта (1) более чем в 2 реза.


Предварительные выводы:
1. Партиции должны создаваться в любом случае, так как при росте данных все больше ощущается разница между вариантом (3)  и (1) 
2. С партициями при этом нельзя работать "в лоб" через обычные объединения если в запросе не используются индексные фильтры ибо при объединении SEQ SCAN начинает свою работу после тяжелого объединения и это полный высад
3. А работать надо как с хранимыми агрегатами - когда агрегация собирается до объединения
4. А вообще так-то такие запросы не должны в норме возникать в системах с большим потоком - либо они должны иметь четкие фильтры в индексах, либо хранимые агрегаты, либо иметь четкие границы, пригодные для партицирования и паралельных расчетов (смотри вариант (4)), как вариант хранимые агрегированные виды по каждой партиции или объединении.


Не надо пускать эту тему на самотек, но и не надо придумывать лишнего. Надо
1. Спланировать партиции в любом случае
2. Идентифицировать как можно раньше тяжелые запросы и постараться их ПРЕДВЫЧИСЛЯТЬ на уровне партиции при закрытии периода, как это всегда и делается в системах типа бухгалтерии
3. Куб естественно не сможет обслужить SELECT ALL FROM ALL AND GROUP соответственно по такие запросы в любом случае нужны либо свои оптимиизированные кубы либо хранимые агрегаты как в классическом OLAP

